# 代码框架

## 项目整体流程

1. **数据准备与航线筛选** (`select_airline.py`): 从原始数据中筛选出有效航线，并生成航线报告（包括航线起点、终点、有效数据比例、时间跨度等）。
2. **时间粒度控制** (`time_granularity.py`): 根据设定的时间粒度（月、季、年）对数据进行聚合，并提供相应的滞后阶数、滑动窗口大小和假期月份等配置。
3. **数据预处理** (`FeatureEngineer.py`中的`DataPreprocessor`): 对每条航线的数据进行缺失值填充、归一化等预处理。
4. **特征工程** (`FeatureEngineer.py`中的`FeatureBuilder`): 构建时间特征（年、月、季度等）、假期特征、滞后特征、滑动特征，并可选加入时间序列预测特征。
5. **模型配置** (`create_model.py`): 根据时间粒度和模型类型（LightGBM或XGBoost）返回配置好的模型。
6. **时间序列模型** (`TS_model.py`): 提供ARIMA和Prophet模型，用于生成时间序列预测特征。
7. **航线模型训练与预测** (`train_model.py`, `train_model_split.py`, `train_models.py`, `train_models_split.py`): 针对单条航线或多条航线进行模型训练、评估和未来预测。
8. **模型评估** (`model_evaluation.py`): 计算并报告RMSE、MAE、MAPE、R²等评估指标。

### 各模块详细说明

#### 1. 数据准备与航线筛选 (`select_airline.py`)

- **功能**: 从原始数据中提取所有唯一的航线（起点和终点），并计算每条航线的有效数据比例（非空且非零的比例）以及时间跨度。
- **输入**: 原始数据文件 `final_data_0622.csv`

- **输出**: 航线报告文件 `route_data_report.csv`，包含列：`Origin`, `Destination`, `Total_Cells`, `Valid_Cells`, `Valid_Ratio`, `Min_YearMonth`, `Max_YearMonth`

- **关键步骤**:
  - 读取原始数据，获取唯一的航线对（起点和终点）。
  - 使用`AirlineRouteModel`获取每条航线的数据。
  - 计算每条航线的总单元格数、有效单元格数、有效比例以及时间跨度（最小和最大年月）。
  -  按有效比例排序并保存结果。

#### 2. 时间粒度控制 (`time_granularity.py`)

- **功能**: 根据设定的时间粒度（月、季、年）对数据进行聚合，并提供相应的配置（滞后阶数、滑动窗口大小、假期月份等）。

- **类**: `TimeGranularityController`

- **方法**:
  - `__init__(granularity)`: 初始化粒度（'monthly', 'quarterly', 'yearly'）。
  - `resample_data(df, date_col)`: 按指定粒度聚合数据（例如，季度数据将按月聚合为季度）。
  - `get_lags()`: 返回当前粒度下推荐的滞后阶数列表。
  - `get_windows()`: 返回当前粒度下推荐的滑动窗口大小列表。
  - `get_holiday_months()`: 返回当前粒度下假期月份列表。
  - `get_freq()`: 返回当前粒度的频率字符串（用于时间序列操作）。

#### 3. 数据预处理 (`FeatureEngineer.py`中的`DataPreprocessor`)

- **功能**: 对数据进行预处理，包括缺失值填充（区分经济数据列和非经济数据列）、归一化等。

- **类**: `DataPreprocessor`

- **参数**:
  - `fill_method`: 填充方法（'interp', 'zero', 'regression'）。
  - `max_invalid_ratio`: 最大允许缺失值比例。
  - `min_fit_points`: 回归填充所需的最小有效点数。
  - `normalize`: 是否归一化。
  - `time_col`: 时间列名称。
  - `non_economic_tail_window`: 非经济数据列尾部填充使用的窗口大小（月数）。
  - `non_economic_model`: 非经济数据列尾部填充使用的模型（'ses', 'linear', 'lastn', 'arima', 'sarima', 'holt'）。
  - `economic_prefixes`: 经济数据列的前缀列表。

- **方法**:
  -  `fit(X, y)`: 识别0-1列和经济数据列，并收集列统计信息（均值、中位数等）。
  -  `transform(X)`: 执行预处理，包括：1）将非0-1列的0值转换为NaN。2）填充缺失值（头部用第一个有效值填充，中间用指定方法填充，尾部根据列类型采用不同策略）。3）对0-1列用众数填充缺失值。4）可选归一化（非0-1列）。

#### 4. 特征工程 (`FeatureEngineer.py`中的`FeatureBuilder`)

- **功能**: 构建特征，包括时间特征（年、月、季度、假期标志）、滞后特征、滑动窗口特征，以及可选的时间序列预测特征。

- **类**: `FeatureBuilder`

- **参数**:
  -  `granularity_controller`: 时间粒度控制器实例。
  -  `lags`: 滞后阶数列表（默认使用粒度控制器的推荐值）。
  -  `windows`: 滑动窗口大小列表（默认使用粒度控制器的推荐值）。
  -  `holiday_months`: 假期月份列表（默认使用粒度控制器的推荐值）。
  -  `add_ts_forecast`: 是否添加时间序列预测特征。
  - `ts_model`: 时间序列预测模型对象（如ARIMA）。

- **方法**:

- `fit(X, y)`: 如果需要添加时间序列预测特征，则训练时间序列模型。

- `transform(X)`: 构建特征，包括：
  - 添加时间特征（年、月、季度、假期标志）。
  - 添加滞后特征（目标列的滞后值）。
  - 添加时间序列预测特征（如果启用）。

#### 5. 模型配置 (`create_model.py`)

- **功能**: 根据时间粒度和模型类型返回配置好的模型（LightGBM或XGBoost）。

- **函数**: `get_model(granularity, model_type)`

- **参数**:
  -  `granularity`: 时间粒度（'monthly', 'quarterly', 'yearly'）。
  - `model_type`: 模型类型（'lgb'或'xgb'）。

- **返回**: 配置好的模型实例（LGBMRegressor或XGBRegressor），不同粒度的模型参数不同（如树的深度、叶子最小样本数等）。

#### 6. 时间序列模型 (`TS_model.py`)

- **功能**: 提供时间序列模型（ARIMA、Prophet）用于生成时间序列预测特征。

- **基类**: `BaseTSModel`（定义接口）

- **实现类**:
  - `ARIMAModel`: 实现ARIMA模型，包括拟合和预测方法。
  -  `ProphetModel`: 实现Prophet模型，包括拟合和预测方法。

#### 7. 航线模型训练与预测 (`train_model.py`, `train_model_split.py`, `train_models.py`, `train_models_split.py`)

- **功能**: 对单条或多条航线进行模型训练、评估和未来预测。

- **单条航线处理** (`train_model.py`, `train_model_split.py`):
  1. 配置数据预处理、特征工程、时间粒度控制。
  2. 准备训练集和测试集。
  3. 训练模型（LightGBM或XGBoost）并评估。
  4. 进行未来预测。
  5. 可视化结果（实际值、训练预测、测试预测、未来预测）。

- **多条航线并行处理** (`train_models.py`, `train_models_split.py`):
  1. 从航线报告中筛选有效比例大于阈值的航线。
  2. 使用多进程并行处理每条航线（调用单条航线处理函数）。
  3. 保存每条航线的训练数据、评估结果、特征重要性图和预测图。

|         文件名称          |       主要功能       | 数据处理规模 | 并行处理 |                  未来预测策略                  |
| :-----------------------: | :------------------: | :----------: | :------: | :--------------------------------------------: |
|    **train_model.py**     | 单航线模型训练与预测 |   单条航线   |    ❌     |           使用训练集模型直接预测未来           |
| **train_model_split.py**  | 单航线模型训练与预测 |   单条航线   |    ❌     | ==**使用完整数据集重新训练模型**==后再预测未来 |
|    **train_models.py**    |   批量航线模型训练   | **多条航线** |    ✅     |           使用训练集模型直接预测未来           |
| **train_models_split.py** |   批量航线模型训练   | **多条航线** |    ✅     | ==**使用完整数据集重新训练模型**==后再预测未来 |

#### 8. 模型评估 (`model_evaluation.py`)

- **功能**: 计算并报告评估指标。

- **类**: `ModelEvaluator`

- **方法**:
  - `__init__(y_true, y_pred)`: 初始化真实值和预测值。
  - `calculate_metrics()`: 计算RMSE、MAE、MAPE、R²。
  - `report(name, return_str)`: 打印或返回评估报告。
- **评估指标**：
  1. RMSE (Root Mean Square Error) - 均方根误差

     - **公式**：$\text{RMSE} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}$

     - **含义**：预测值与真实值偏差的平方和的平均值的平方根

     - **值域意义**：值越小越好（0表示完美预测）；对较大误差更敏感（平方效应）；单位与原始数据相同

  2. MAE (Mean Absolute Error) - 平均绝对误差

     - **公式**：$\text{MAE} = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|$

     - **含义**：预测值与真实值绝对偏差的平均值

     - **值域意义**：值越小越好（0表示完美预测）；比RMSE对异常值更鲁棒；单位与原始数据相同
  3. MAPE (Mean Absolute Percentage Error) - 平均绝对百分比误差

     - **公式**：$\text{MAPE} = \frac{100%}{n}\sum_{i=1}^{n}\left|\frac{y_i - \hat{y}_i}{y_i}\right|$

     - **含义**：相对误差的绝对值的平均值（百分比形式）

     - **值域意义**：值越小越好（0%表示完美预测）；无量纲指标，适合不同量级数据比较；当真实值接近0时会放大误差
  4. R² (R-Squared) - 决定系数
     - **公式**：$R^2 = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y}*i)^2}{\sum*{i=1}^{n}(y_i - \bar{y})^2}$
     - **含义**：模型解释的方差占总方差的比例
     - **值域意义**：**0-1**：值越大越好；**1**：完美拟合；**0**：等同于均值预测；**<0**：比均值预测更差

## 模型调试

### 1. 月度模型

#### 1. lightgbm

```python
model = lgb.LGBMRegressor(
    n_estimators=100,
    max_depth=7,
    min_child_samples=10,         # 更小的叶子节点允许更多分裂
    min_split_gain=0.0,           # 放宽分裂的最小增益门槛
    learning_rate=0.1,
    random_state=42
)
```

> Train Metrics:
> RMSE: 20142.52
> MAE: 13563.06
> MAPE: 2.03%
> R²: 0.9962
>
> Test Metrics:
> RMSE: 44014.36
> MAE: 33381.18
> MAPE: 3.45%
> R²: -0.2026

![Figure_1](./assets/Figure_1.png)

#### 2. xgboost

```python
model = xgb.XGBRegressor(
    n_estimators=100,
    max_depth=3,
    learning_rate=0.1,
    reg_lambda=1,  
    random_state=42
)
```

> Train Metrics:
> RMSE: 29597.58
> MAE: 23166.88
> MAPE: 3.19%
> R²: 0.9919
>
> Test Metrics:
> RMSE: 68475.98
> MAE: 55822.98
> MAPE: 5.81%
> R²: -1.9108

![Figure_1](./assets/Figure_1-1749991744094-2.png)

#### 3. lightgbm+ARIMA

```python
model = lgb.LGBMRegressor(
    n_estimators=100,
    max_depth=7,
    min_child_samples=10,         # 更小的叶子节点允许更多分裂
    min_split_gain=0.0,           # 放宽分裂的最小增益门槛
    learning_rate=0.1,
    random_state=42
)
```

> RMSE: 20232.00
> MAE: 13544.49
> MAPE: 1.94%
> R²: 0.9962
>
> Test Metrics:
> RMSE: 35404.34
> MAE: 29959.06
> MAPE: 3.15%
> R²: 0.2219

![Figure_1](./assets/Figure_1-1750061883777-1.png)



### 2. 季度模型

#### 1. lightgbm

```python
model = lgb.LGBMRegressor(
    n_estimators=100,
    max_depth=3,
    min_child_samples=1,         # 更小的叶子节点允许更多分裂
    min_split_gain=0.0,           # 放宽分裂的最小增益门槛
    learning_rate=0.1,
    random_state=42
)
```

> Train Metrics:
> RMSE: 10973.12
> MAE: 8649.34
> MAPE: 0.41%
> R²: 0.9999
>
> Test Metrics:
> RMSE: 21524.44
> MAE: 17384.81
> MAPE: 0.62%
> R²: 0.9055

![Figure_1](./assets/Figure_1-1749991969419-4.png)

如果是4个季度预测

```python
model = lgb.LGBMRegressor(
    n_estimators=100,
    max_depth=2,
    min_child_samples=2,         # 更小的叶子节点允许更多分裂
    min_split_gain=0.0,           # 放宽分裂的最小增益门槛
    learning_rate=0.1,
    random_state=42
)
```

> Train Metrics:
> RMSE: 62724.25
> MAE: 49349.49
> MAPE: 2.29%
> R²: 0.9956
>
> Test Metrics:
> RMSE: 294229.76
> MAE: 242816.17
> MAPE: 8.76%
> R²: -7.7726

![Figure_1](./assets/Figure_1-1750063773028-1.png)

#### 2. xgboost

```python
model = xgb.XGBRegressor(
    n_estimators=100,
    max_depth=3,
    learning_rate=0.1,
    reg_lambda=1,  
    random_state=42
)
```

> Train Metrics:
> RMSE: 66660.42
> MAE: 50178.15
> MAPE: 2.39%
> R²: 0.9949
>
> Test Metrics:
> RMSE: 94505.19
> MAE: 78335.88
> MAPE: 2.80%
> R²: -0.8210

![Figure_1](./assets/Figure_1-1749992183764-6.png)

#### 3. lightgbm+ARIMA

```python
model = lgb.LGBMRegressor(
    n_estimators=100,
    max_depth=3,
    min_child_samples=1,         # 更小的叶子节点允许更多分裂
    min_split_gain=0.0,           # 放宽分裂的最小增益门槛
    learning_rate=0.1,
    random_state=42
)
```

> Train Metrics:
> RMSE: 11453.98
> MAE: 9108.52
> MAPE: 0.42%
> R²: 0.9998
>
> Test Metrics:
> RMSE: 63372.73
> MAE: 57355.28
> MAPE: 2.00%
> R²: 0.1811

![Figure_1](./assets/Figure_1-1750062599117-5.png)

如果是4个季度预测

```python
model = lgb.LGBMRegressor(
    n_estimators=100,
    max_depth=2,
    min_child_samples=2,         # 更小的叶子节点允许更多分裂
    min_split_gain=0.0,           # 放宽分裂的最小增益门槛
    learning_rate=0.1,
    random_state=42
)
```

> Train Metrics:
> RMSE: 65317.79
> MAE: 50116.28
> MAPE: 2.30%
> R²: 0.9953
>
> Test Metrics:
> RMSE: 229204.38
> MAE: 206328.07
> MAPE: 7.40%
> R²: -4.3235

![Figure_1](./assets/Figure_1-1750063855243-3.png)

### 3. 年度模型

#### 1. lightgbm

```python
model = lgb.LGBMRegressor(
    n_estimators=100,
    max_depth=3,
    min_child_samples=1,         # 更小的叶子节点允许更多分裂
    min_split_gain=0.0,           # 放宽分裂的最小增益门槛
    learning_rate=0.1,
    random_state=42
)
```

> Train Metrics:
> RMSE: 659.53
> MAE: 540.34
> MAPE: 0.01%
> R²: 1.0000
>
> Test Metrics:
> RMSE: 5699641.39
> MAE: 5699641.39
> MAPE: 53.56%
> R²: nan

![Figure_1](./assets/Figure_1-1749992297687-8.png)

#### 2. lightgbm+ARIMA

```python
model = lgb.LGBMRegressor(
    n_estimators=100,
    max_depth=3,
    min_child_samples=1,         # 更小的叶子节点允许更多分裂
    min_split_gain=0.0,           # 放宽分裂的最小增益门槛
    learning_rate=0.1,
    random_state=42
)
```

> Train Metrics:
> RMSE: 659.53
> MAE: 540.34
> MAPE: 0.01%
> R²: 1.0000
>
> Test Metrics:
> RMSE: 5699641.39
> MAE: 5699641.39
> MAPE: 53.56%
> R²: nan

![Figure_1](./assets/Figure_1-1750062460341-3.png)

